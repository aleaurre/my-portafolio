---
title: "M√°s all√° del An√°lisis Tiempo‚ÄìFrecuencia y Transformaciones Avanzadas para Preprocesamiento y Evaluaci√≥n de Se√±ales Ac√∫sticas."
publishedAt: "2025-11-25"
tag: "Curso: Ingenier√≠a de Datos"
image: "/practica14/portadab.jpg"
---

# An√°lisis avanzado de eventos, tono y robustez de MFCC en UrbanSound8K

## Introducci√≥n

En este bonus se extiende la pr√°ctica de audio original para explorar con mayor detalle el comportamiento temporal y espectral de se√±ales reales del dataset **UrbanSound8K**. El punto de partida es la carga masiva de los audios del corpus, de donde se seleccionan dos ejemplos concretos, `101415-3-0-2.wav` y `101415-3-0-3.wav`, ambos normalizados a **4 segundos de duraci√≥n** y una frecuencia de muestreo de **48 kHz**, lo que produce vectores de 192000 muestras por archivo.

Sobre estos audios se aplican las mismas funciones de preprocesamiento de la pr√°ctica 14 (carga, forzado a mono y padding o recorte a duraci√≥n fija) para garantizar que cualquier comparaci√≥n posterior no est√© sesgada por diferencias triviales en longitud o configuraci√≥n de canales. Una vez estandarizados, se avanza hacia cuatro l√≠neas de an√°lisis: detecci√≥n de eventos transitorios, caracterizaci√≥n tonal mediante cromagrama y tonnetz, estudio de la energ√≠a temporal a trav√©s de RMS y evaluaci√≥n de la sensibilidad de los **MFCC** frente a la adici√≥n de ruido blanco. Finalmente, se entrena un clasificador lineal muy simple sobre MFCC para ilustrar c√≥mo estos descriptores pueden alimentar un modelo supervisado, a√∫n en un escenario m√≠nimo con solo dos clases de ejemplo.

---

## Marco te√≥rico

El dise√±o del bonus se apoya en tres bloques conceptuales. En primer lugar, la **detecci√≥n de onsets** u onsets temporales busca localizar instantes en los que se produce un cambio abrupto en la envolvente de energ√≠a o en el espectro; estos puntos suelen corresponder a golpes, transitorios o eventos ac√∫sticos bien definidos. Librosa implementa este procedimiento a partir de un *onset envelope* y de umbrales adaptativos, devolviendo una secuencia de tiempos donde se detectan dichos eventos.

En segundo lugar, el an√°lisis tonal se articula mediante el **cromagrama** y el **tonnetz**. El cromagrama proyecta el contenido espectral sobre las doce clases de pitch de la escala occidental, permitiendo visualizar qu√© notas o regiones tonales dominan en cada momento. El tonnetz, por su parte, utiliza una representaci√≥n geom√©trica de las relaciones de intervalo para analizar la cercan√≠a arm√≥nica entre acordes y centros tonales; resulta especialmente √∫til cuando la se√±al contiene patrones musicales o pseudo-musicales, incluso en entornos de ruido urbano.

El tercer bloque est√° formado por dos componentes complementarios. Por un lado, la **energ√≠a RMS por frame** describe c√≥mo se reparte la intensidad del sonido a lo largo del tiempo y es clave para identificar secciones m√°s activas o silencios relativos. Por otro, los **coeficientes MFCC** (Mel-Frequency Cepstral Coefficients) encapsulan la envolvente espectral filtrada en escala Mel, lo que los convierte en descriptores de timbre muy eficaces. Evaluar su sensibilidad al ruido blanco, introduciendo un SNR controlado, permite estimar hasta qu√© punto estos descriptores se mantienen estables ante degradaciones de la se√±al. Finalmente, aplicar un clasificador como una **SVM lineal** sobre los MFCC ilustra el paso desde la descripci√≥n de la se√±al hacia la toma de decisiones supervisada, aunque en este bonus ello se haga en una escala m√≠nima con etiquetas dummy.

---

## Selecci√≥n de audios y preprocesamiento

El script recorre el √°rbol de directorios de UrbanSound8K y localiza **8732 archivos .wav**, una cifra que se muestra como verificaci√≥n del correcto acceso al dataset. A continuaci√≥n selecciona los dos primeros archivos encontrados, `101415-3-0-2.wav` y `101415-3-0-3.wav`, y los pasa por la funci√≥n `preprocess_audio`, que a su vez utiliza `load_audio` y `pad_or_trim` para garantizar una duraci√≥n fija de 4 segundos y formato mono. Ambas se√±ales resultantes comparten forma `(192000,)` y frecuencia de muestreo 48000 Hz, lo que garantiza un punto de partida homog√©neo para el an√°lisis posterior.

<table>
  <thead>
    <tr>
      <th>Audio</th>
      <th>Nombre de archivo</th>
      <th>Duraci√≥n fija</th>
      <th>Forma del vector</th>
      <th>Sample rate</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Audio 1</td>
      <td>101415-3-0-2.wav</td>
      <td>4.0 s</td>
      <td>(192000,)</td>
      <td>48000 Hz</td>
    </tr>
    <tr>
      <td>Audio 2</td>
      <td>101415-3-0-3.wav</td>
      <td>4.0 s</td>
      <td>(192000,)</td>
      <td>48000 Hz</td>
    </tr>
  </tbody>
</table>

La tabla resume las propiedades estructurales fundamentales de los dos audios seleccionados y confirma que ambos han pasado por un proceso id√©ntico de estandarizaci√≥n. Esto elimina cualquier fuente de variabilidad no deseada derivada de diferencias en formato, duraci√≥n o frecuencia de muestreo, asegurando que las comparaciones posteriores ‚Äîonsets, tonalidad, energ√≠a y sensibilidad de MFCC‚Äî reflejen √∫nicamente diferencias intr√≠nsecas de la se√±al y no artefactos del procesamiento. Que ambos vectores posean exactamente 192000 muestras implica que cada an√°lisis opera sobre ventanas temporales an√°logas, garantizando una correspondencia temporal estricta entre los distintos indicadores calculados.

---

## Detecci√≥n de eventos transitorios (onsets)

Sobre el segundo audio preprocesado se construye un eje temporal lineal y se calcula la envolvente de onsets mediante `librosa.onset.onset_strength`. Con esa envolvente se obtienen los frames donde se detectan eventos y, finalmente, se convierten en tiempos en segundos. El resultado es una secuencia de **25 onsets** distribuidos principalmente entre los 0.6 y los 3.5 segundos de la se√±al, lo que revela una estructura rica en eventos intermedios y una relativa calma al inicio y al final.

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica14/bonus1.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={200}
  />
</div>


En la figura se observa el waveform del audio 2, superpuesto con l√≠neas verticales rojas discontinuas en los tiempos de onset. Visualmente se aprecia c√≥mo estas l√≠neas suelen coincidir con picos pronunciados de amplitud, indicando que el algoritmo es capaz de capturar golpes o transiciones energ√©ticas relevantes. La concentraci√≥n de onsets en la regi√≥n central refuerza la idea de que la se√±al posee una parte media muy activa, rodeada por zonas de menor densidad de eventos al principio y al final. Esta distribuci√≥n tiene implicaciones directas en tareas como segmentaci√≥n, sincronizaci√≥n o detecci√≥n de patrones r√≠tmicos.

---

## An√°lisis tonal: cromagrama y tonnetz

El bonus contin√∫a con la extracci√≥n de un **cromagrama** a partir de la STFT del audio 2, representando la energ√≠a de las doce clases de pitch en funci√≥n del tiempo. El resultado es una matriz de tama√±o (12, 376) que se visualiza mediante `librosa.display.specshow`. En paralelo, se calcula el **tonnetz** sobre la componente arm√≥nica de la se√±al, obteniendo una matriz de tama√±o (6, 376) que captura relaciones de intervalo y estabilidad arm√≥nica.

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica14/bonus2.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={200}
  />
</div>

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica14/bonus3.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={200}
  />
</div>

En el panel superior del gr√°fico se distinguen bandas horizontales m√°s intensas en ciertas clases de pitch, lo que sugiere la presencia de componentes tonales recurrentes, incluso si el contexto sonoro es urbano y no estrictamente musical. Estas bandas se activan y desactivan a lo largo del tiempo, delineando una especie de firma tonal del entorno. En el panel inferior, el tonnetz muestra trayectorias suaves y zonas donde algunas dimensiones se intensifican m√°s que otras, lo que indica relaciones arm√≥nicas relativamente estables. Aunque UrbanSound8K no est√° dise√±ado como corpus musical, la presencia de patrones tonales es relevante para tareas como clasificaci√≥n de ambientes, detecci√≥n de sirenas o identificaci√≥n de se√±ales ac√∫sticas estructuradas.

<table>
  <thead>
    <tr>
      <th>Representaci√≥n</th>
      <th>Shape</th>
      <th>Descripci√≥n</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cromagrama</td>
      <td>(12, 376)</td>
      <td>12 clases de pitch a lo largo de 376 frames temporales</td>
    </tr>
    <tr>
      <td>Tonnetz</td>
      <td>(6, 376)</td>
      <td>6 dimensiones arm√≥nicas sobre los mismos 376 frames</td>
    </tr>
  </tbody>
</table>

El contraste entre las dimensiones del cromagrama y las del tonnetz revela la diferencia de granularidad entre ambas representaciones. Mientras el cromagrama distribuye la energ√≠a espectral en doce clases de pitch, capturando as√≠ la actividad tonal directa en cada frame, el tonnetz reconfigura esos mismos datos en un espacio de seis dimensiones que codifica relaciones arm√≥nicas internas. Esta reducci√≥n estructurada permite identificar coherencias musicales o pseudo-musicales incluso en se√±ales urbanas, donde la tonalidad no es expl√≠cita. La coincidencia en el n√∫mero de frames entre ambas matrices indica que sus din√°micas temporales pueden compararse de forma directa, facilitando interpretaciones complementarias entre tono y armon√≠a.

---

## Energ√≠a temporal (RMS)

Para caracterizar la din√°mica global de la se√±al se calcula la energ√≠a RMS por frame mediante `librosa.feature.rms`. Con los tiempos asociados producidos por `librosa.times_like`, se grafica la curva de energ√≠a a lo largo de los 4 segundos de audio.

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica14/bonus4.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={200}
  />
</div>

La figura muestra una serie de picos de energ√≠a que coinciden con la distribuci√≥n de onsets detectados previamente: la energ√≠a se mantiene baja en los primeros instantes, aumenta abruptamente con una secuencia de pulsos pronunciados en la regi√≥n central y desciende de manera progresiva hacia el final. Esta lectura confirma que el audio contiene una sucesi√≥n de eventos bien definidos, separados por intervalos de menor intensidad, lo que puede ser interpretado como golpes, ruidos intermitentes o elementos de una textura urbana r√≠tmicamente estructurada. La coherencia entre el RMS y los onsets refuerza la validez del an√°lisis temporal realizado.

---

## Sensibilidad de MFCC al ruido blanco

El siguiente paso consiste en evaluar c√≥mo reaccionan los **MFCC** frente a la introducci√≥n de ruido blanco con **SNR = 10 dB**, una relaci√≥n se√±al‚Äìruido relativamente agresiva. Para ello se genera una versi√≥n ruidosa del audio 2 (`y2_noisy`) utilizando la funci√≥n `add_white_noise`, que ajusta la amplitud del ruido en funci√≥n del RMS de la se√±al original. Luego se extraen los MFCC de la se√±al limpia y de la ruidosa, y se calcula la diferencia absoluta entre cada par de coeficientes, construyendo un `DataFrame` con estas diferencias.

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica14/bonus5.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={400}
  />
</div>

El gr√°fico de barras resultante ordena los coeficientes por su variaci√≥n absoluta y permite observar que algunos MFCC ‚Äîsobre todo los primeros, asociados a la forma global de la envolvente espectral‚Äî son mucho m√°s sensibles al ruido que otros, mientras que los coeficientes de orden mayor muestran cambios m√°s moderados. Esto sugiere que, bajo condiciones de fuerte ruido blanco, la parte m√°s gruesa del timbre se ve significativamente afectada, pero ciertas sutilezas espectrales se mantienen relativamente estables. Este tipo de an√°lisis es crucial a la hora de dise√±ar sistemas robustos: permite decidir si conviene descartar los coeficientes m√°s vol√°tiles, aplicar t√©cnicas de denoising o ajustar el pipeline de extracci√≥n para entornos ruidosos.

<table>
  <thead>
    <tr>
      <th>Aspecto</th>
      <th>Descripci√≥n</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ruido a√±adido</td>
      <td>Ruido blanco con SNR = 10 dB respecto de la se√±al original</td>
    </tr>
    <tr>
      <td>Comparaci√≥n</td>
      <td>MFCC extra√≠dos de se√±al limpia vs. se√±al ruidosa</td>
    </tr>
    <tr>
      <td>M√©trica</td>
      <td>Diferencia absoluta por coeficiente y estad√≠stica agregada en un DataFrame</td>
    </tr>
    <tr>
      <td>Hallazgo principal</td>
      <td>Los primeros MFCC son notablemente m√°s sensibles al ruido que los coeficientes de orden alto</td>
    </tr>
  </tbody>
</table>

La tabla destaca c√≥mo el ruido blanco afecta diferencialmente a los coeficientes cepstrales: mientras los primeros MFCC ‚Äîvinculados a la envolvente global del espectro‚Äî muestran una susceptibilidad marcada, los de orden superior mantienen variaciones m√°s acotadas. Esta observaci√≥n tiene implicaciones pr√°cticas profundas: sugiere que, bajo condiciones de grabaci√≥n adversas, los descriptores m√°s representativos del timbre general pueden degradarse con facilidad, lo que impactar√≠a en tareas de clasificaci√≥n o reconocimiento. En cambio, la estabilidad relativa de los MFCC superiores puede aprovecharse para mejorar la robustez del sistema, ya sea ponderando coeficientes, filtrando ruido o eligiendo subconjuntos m√°s resistentes de features.

---

## Clasificador b√°sico basado en MFCC

Como cierre del bonus, se construye un peque√±o experimento supervisado. A partir de los audios 1 y 2, ya preprocesados, se extraen sus MFCC y se arma un `DataFrame` de entrenamiento con ambas observaciones. Se definen etiquetas dummy `{0: "clase_A", 1: "clase_B"}`, que no pretenden representar categor√≠as sem√°nticas reales del dataset, sino simplemente habilitar la existencia de un modelo de clasificaci√≥n.

Los features se escalan con `StandardScaler`, y a continuaci√≥n se entrena una **SVM lineal** (`SVC(kernel="linear", probability=True)`) sobre este conjunto m√≠nimo. El objetivo no es evaluar desempe√±o (dado que solo hay dos muestras), sino ilustrar c√≥mo los MFCC pueden conectarse a un modelo que genera probabilidades y predicciones de clase. Como ejercicio final, se vuelve a extraer el vector MFCC del audio 2, se transforma con el mismo `scaler` y se pasa por el clasificador, que devuelve la etiqueta `"clase_B"` para ese archivo.

<table>
  <thead>
    <tr>
      <th>Componente</th>
      <th>Rol en el pipeline</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>MFCC</td>
      <td>Vector de caracter√≠sticas base para cada audio</td>
    </tr>
    <tr>
      <td>StandardScaler</td>
      <td>Normaliza cada dimensi√≥n de los MFCC antes de entrenar</td>
    </tr>
    <tr>
      <td>SVM lineal</td>
      <td>Clasificador supervisado con kernel lineal y salida probabil√≠stica</td>
    </tr>
    <tr>
      <td>Etiquetas dummy</td>
      <td>Asignan ‚Äúclase_A‚Äù al audio 1 y ‚Äúclase_B‚Äù al audio 2</td>
    </tr>
    <tr>
      <td>Predicci√≥n de ejemplo</td>
      <td>El modelo clasifica 101415-3-0-3.wav como ‚Äúclase_B‚Äù</td>
    </tr>
  </tbody>
</table>

Aunque el experimento emplea √∫nicamente dos ejemplos, la tabla ilustra con claridad el flujo completo de un pipeline supervisado: extracci√≥n de features, normalizaci√≥n, modelado y predicci√≥n. La SVM lineal act√∫a aqu√≠ como una prueba conceptual de que los MFCC contienen suficiente informaci√≥n discriminativa para que un modelo, aun con muy pocos datos, logre separar las observaciones en un espacio de caracter√≠sticas. La asignaci√≥n consistente de la clase "clase_B" al segundo audio confirma que el modelo captura diferencias reales en la estructura espectral entre ambas se√±ales. Esta demostraci√≥n, aunque m√≠nima, valida la idea central del bonus: los MFCC funcionan como puente entre el an√°lisis de se√±al y las tareas de decisi√≥n autom√°tica.

---

## Conclusiones del bonus

El bonus de la pr√°ctica 14 muestra c√≥mo, a partir de dos audios concretos de UrbanSound8K, es posible construir un mini laboratorio de an√°lisis temporal, tonal y espectral que va m√°s all√° de la mera visualizaci√≥n del espectrograma. La detecci√≥n de onsets revela una estructura temporal rica en eventos, el cromagrama y el tonnetz evidencian la presencia de patrones tonales significativos incluso en se√±ales urbanas, y la curva RMS aporta una visi√≥n clara de c√≥mo se distribuye la energ√≠a a lo largo de los 4 segundos de duraci√≥n.

La evaluaci√≥n de la sensibilidad de los MFCC frente a ruido blanco con SNR bajo demuestra que no todos los coeficientes se comportan igual: algunos son extremadamente vulnerables a la degradaci√≥n, mientras otros se mantienen relativamente estables. Este hallazgo invita a pensar en estrategias de selecci√≥n o ponderaci√≥n de caracter√≠sticas cuando se dise√±an sistemas robustos para entornos ruidosos. Finalmente, el peque√±o experimento con SVM ilustra que, incluso en condiciones m√≠nimas, los MFCC constituyen una base razonable para modelos supervisados, ofreciendo un puente natural entre an√°lisis de se√±al y tareas de clasificaci√≥n.

En conjunto, este bonus consolida la idea de que un buen pipeline de audio no se limita a calcular features, sino que los somete a pruebas de comportamiento ‚Äîruido, estructura temporal, contenido tonal‚Äî y los sit√∫a dentro de una arquitectura que va desde la onda cruda hasta la decisi√≥n de un clasificador.

---

## Evidencias

Para consultar el c√≥digo √≠ntegro, las funciones aplicadas, la generaci√≥n de gr√°ficos y los resultados intermedios de la pr√°ctica, se adjunta el notebook original:

üìé **Google Colab:** [Abrir notebook](https://colab.research.google.com/drive/1lmWH571HxBngOqEiTBfIbCpdyWhofUeS?usp=sharing)

