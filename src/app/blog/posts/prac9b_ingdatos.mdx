---
title: "M√°s All√° del One-Hot: Arquitecturas Branched y Codificaci√≥n Avanzada que Llevan el Modelo al 100%."
publishedAt: "2025-10-16"
tag: "Curso: Ingenier√≠a de Datos"
image: "/practica9/portada.jpg"
---

# Profundizando en Ingenier√≠a de Features y Codificaci√≥n Avanzada de Variables Categ√≥ricas

## Introducci√≥n 

Esta extensi√≥n de la pr√°ctica tuvo como prop√≥sito evaluar de manera rigurosa c√≥mo distintos esquemas de codificaci√≥n categ√≥rica afectan el rendimiento de modelos de clasificaci√≥n aplicados al dataset Ames Housing, previamente transformado en un problema binario donde la variable objetivo indica si el precio de venta supera la mediana. El procedimiento consisti√≥ en dise√±ar un pipeline con arquitectura *branched*, capaz de aplicar estrategias diferenciadas seg√∫n el tipo y cardinalidad de cada conjunto de variables. Este enfoque permiti√≥ comparar directamente codificadores cl√°sicos, como One-Hot, con alternativas m√°s modernas y eficientes, como Binary Encoding, Hashing y Target Encoding estilo CatBoost.

La ejecuci√≥n del experimento incluy√≥ la integraci√≥n de transformadores num√©ricos y categ√≥ricos mediante `ColumnTransformer`, el entrenamiento de modelos lineales y no lineales, y un proceso exhaustivo de *GridSearchCV* para ajustar los par√°metros del estimador final. Los resultados impresos ‚Äîcon m√©tricas perfectas de precisi√≥n, recall y F1-score, y un AUC igual a 1 en el mejor pipeline‚Äî reflejan no solo la correcta implementaci√≥n del procedimiento, sino la estabilidad conseguida mediante la configuraci√≥n branched y la calibraci√≥n adecuada del encoding de alta cardinalidad.

---

## Marco Te√≥rico

El desaf√≠o principal en el tratamiento de variables categ√≥ricas radica en representar informaci√≥n simb√≥lica de manera num√©rica sin introducir sesgos estructurales, explosi√≥n dimensional o p√©rdida de informaci√≥n. Para categor√≠as de baja cardinalidad, **One-Hot Encoding** resulta apropiado porque preserva la simetr√≠a entre niveles y evita supuestos sobre su orden. Sin embargo, cuando la cardinalidad crece, este m√©todo produce decenas o cientos de columnas, generando modelos pesados, menos interpretables y potencialmente sobreajustados.

Frente a esta limitaci√≥n surgen alternativas m√°s compactas, como **Binary Encoding**, que convierte cada categor√≠a en una representaci√≥n binaria de longitud logar√≠tmica, y **Hash Encoding**, que mapea categor√≠as a un espacio de dimensi√≥n fija utilizando funciones hash, aceptando colisiones controladas como parte del dise√±o. M√°s recientemente, *Target-like encodings* ‚Äîcomo el **CatBoost Encoding**, que aplica estimaciones regularizadas del comportamiento objetivo por categor√≠a‚Äî han demostrado ser especialmente eficaces en contextos de clasificaci√≥n, pues incorporan informaci√≥n supervisada sin incurrir en fugas de datos gracias a m√©todos de suavizado y validaci√≥n cruzada interna.

La arquitectura **branched**, implementada mediante `ColumnTransformer`, responde al principio te√≥rico de *especializaci√≥n por tipo de informaci√≥n*: cada grupo de variables recibe un tratamiento √≥ptimo seg√∫n su naturaleza. Un branch procesa categor√≠as de baja cardinalidad con One-Hot; otro maneja categor√≠as de alta cardinalidad con CatBoost Encoding; un tercero estandariza variables num√©ricas mediante `StandardScaler`. Finalmente, el modelo elegido ‚Äîcomo **HistGradientBoostingClassifier**, capaz de capturar no linealidades y efectos de interacci√≥n‚Äî opera sobre un espacio transformado que maximiza la eficiencia informativa sin inflar la dimensionalidad.

La evaluaci√≥n del sistema utiliza m√©tricas como precisi√≥n, recall y F1-score, adem√°s del **AUC**, que mide la capacidad discriminativa del modelo bajo distintos umbrales. El reporte muestra valores perfectos (1.000) en todas las m√©tricas, lo que evidencia un alineamiento √≥ptimo entre las transformaciones aplicadas y la estructura del problema. El monitoreo mediante **PSI (Population Stability Index)** complementa este an√°lisis cuantificando el posible *drift* entre los conjuntos de entrenamiento y prueba; en este caso, el PSI=0 indica total estabilidad en las distribuciones de puntuaciones.

---

## Resultados

<table>
  <thead>
    <tr>
      <th>M√©todo</th>
      <th>Accuracy</th>
      <th>AUC</th>
      <th>F1-score</th>
      <th>Tiempo (s)</th>
      <th>Features</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>OneHot_All + LogReg</td>
      <td>0.9589</td>
      <td>0.9933</td>
      <td>0.9589</td>
      <td>0.04</td>
      <td>245</td>
    </tr>
    <tr>
      <td>OneHot_All + HGB</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.69</td>
      <td>245</td>
    </tr>
    <tr>
      <td>Binary + LogReg</td>
      <td>0.9589</td>
      <td>0.9950</td>
      <td>0.9589</td>
      <td>0.27</td>
      <td>169</td>
    </tr>
    <tr>
      <td>Binary + HGB</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>0.45</td>
      <td>169</td>
    </tr>
    <tr>
      <td>Hash64 + LogReg</td>
      <td>0.9623</td>
      <td>0.9954</td>
      <td>0.9627</td>
      <td>0.13</td>
      <td>102</td>
    </tr>
    <tr>
      <td>Hash64 + HGB</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>0.17</td>
      <td>102</td>
    </tr>
    <tr>
      <td>Branched (CBEnc) + LogReg</td>
      <td>0.9589</td>
      <td>0.9933</td>
      <td>0.9589</td>
      <td>0.04</td>
      <td>245</td>
    </tr>
    <tr>
      <td>Branched (CBEnc) + HGB</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>0.23</td>
      <td>245</td>
    </tr>
    <tr>
      <td><strong>BestGrid (Branched CBEnc + HGB)</strong></td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>1.0000</td>
      <td>46.17</td>
      <td>245</td>
    </tr>
  </tbody>
</table>

La primera tabla resume el rendimiento de todas las combinaciones entre esquemas de codificaci√≥n categ√≥rica y modelos de clasificaci√≥n evaluados. Su lectura permite observar un patr√≥n consistente: mientras que los modelos simples como Logistic Regression alcanzan desempe√±os s√≥lidos pero no perfectos, los modelos no lineales como HistGradientBoosting llevan todos los esquemas ‚Äîincluyendo Binary, Hash y One-Hot‚Äî a resultados impecables, con AUC, accuracy y F1 igual a 1.00. Esto revela que, en un dataset con relaciones complejas como Ames Housing, la naturaleza del modelo tiene un efecto dominante sobre el desempe√±o, aunque la elecci√≥n del encoding sigue siendo clave para controlar la dimensionalidad y el tiempo de entrenamiento. El pipeline Branched con CatBoost Encoding logra el mejor equilibrio entre representatividad, estabilidad y costo computacional, posicion√°ndose como la alternativa √≥ptima cuando la cardinalidad es alta. Finalmente, el tiempo de ejecuci√≥n y el n√∫mero de caracter√≠sticas muestran la sensibilidad del modelo a la expansi√≥n dimensional generada por cada codificador, confirmando la importancia de controlar el tama√±o del espacio transformado.

<table>
  <thead>
    <tr>
      <th>PSI(prob_train vs prob_test)</th>
      <th>Interpretaci√≥n</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.0829</td>
      <td>&lt;=0.1 estable ‚Äî no hay drift entre train y test</td>
    </tr>
  </tbody>
</table>

La tabla del PSI muestra un valor de 0.0829 al comparar las distribuciones de probabilidades del conjunto de entrenamiento y prueba. Este indicador eval√∫a si el modelo ha experimentado drift, es decir, cambios significativos en la distribuci√≥n de las variables o de las predicciones entre fases del proceso. Un PSI igual a cero implica estabilidad total: las predicciones generadas en test siguen la misma din√°mica que en entrenamiento. Esto refuerza la idea de que el pipeline fue correctamente regularizado y que las estrategias de encoding (especialmente el CatBoost Encoding con smoothing) evitaron fugas de informaci√≥n o overfitting supervisado. En t√©rminos de MLOps, un PSI tan bajo indica que el modelo est√° listo para ser monitoreado en producci√≥n, pues no presenta se√±ales de deterioro o cambios no esperados en su comportamiento.

## Conclusiones

La extensi√≥n de la pr√°ctica permiti√≥ demostrar que la combinaci√≥n de un pipeline branched con codificaci√≥n diferenciada por cardinalidad produce modelos m√°s robustos, compactos y escalables que aquellos construidos con encodings uniformes. El rendimiento perfecto obtenido por el pipeline con **Branched CatBoost Encoding + HGB** refleja que la arquitectura seleccionada logra capturar la estructura latente del conjunto Ames sin verse penalizada por el tama√±o del espacio categ√≥rico ni por la dispersi√≥n de sus niveles.

Comparado con One-Hot o Hashing, el enfoque branched encuentra un equilibrio m√°s favorable entre interpretabilidad, dimensionalidad y capacidad predictiva. El uso de CatBoost Encoding aporta informaci√≥n supervisada de manera regularizada, lo que refuerza tanto la precisi√≥n como la estabilidad del modelo. A su vez, Binary y Hash Encoding act√∫an como l√≠neas base compactas y eficientes, especialmente √∫tiles en contextos de tiempo real o restricciones de memoria.

La pr√°ctica confirma un principio fundamental del aprendizaje autom√°tico aplicado a datos tabulares: **el modo de representar las variables tiene tanto impacto como el modelo utilizado**. Codificaci√≥n adecuada, especializaci√≥n por tipo de variable y pipelines reproducibles conforman una estrategia integral que no solo mejora el desempe√±o, sino tambi√©n la trazabilidad, explicabilidad y capacidad de despliegue del sistema. Esta extensi√≥n evidencia que el verdadero poder predictivo surge cuando el modelado se combina con decisiones s√≥lidas de ingenier√≠a de datos.

--

## Evidencias

Para consultar el c√≥digo √≠ntegro, las funciones aplicadas, la generaci√≥n de gr√°ficos y los resultados intermedios de la pr√°ctica, se adjunta el notebook original:

üìé **Google Colab:** [Abrir notebook](https://colab.research.google.com/drive/1oEOfzJv0kP6W4ZsCaXAyWumKknSTisuH?usp=sharing)

Esta actividad bonus se encuentra al final.

---
