---
title: "M√°s all√° de la Reducci√≥n Dimensional y Selecci√≥n de Variables en Ames Housing"
publishedAt: "2025-10-24"
tag: "Curso: Ingenier√≠a de Datos"
image: "/practica10/portada.jpg"
---


## Evaluaci√≥n de un Pipeline H√≠brido de Selecci√≥n de Caracter√≠sticas mediante PCA, Informaci√≥n Mutua, RFE, Lasso y Validaci√≥n Cruzada

La extensi√≥n propuesta se centr√≥ en construir y evaluar un pipeline h√≠brido de selecci√≥n de caracter√≠sticas que integrara t√©cnicas cl√°sicas, estad√≠sticas y model-based con el fin de capturar, de forma m√°s robusta, la estructura subyacente del dataset de Ames Housing. A diferencia de los enfoques unidimensionales que suelen depender exclusivamente de PCA o de m√©todos supervisados, la idea fue dise√±ar un sistema capaz de combinar m√∫ltiples criterios: reducci√≥n de dimensionalidad, relevancia estad√≠stica, importancia supervisada y regularizaci√≥n. El objetivo consisti√≥ en evaluar si esta composici√≥n pod√≠a lograr un equilibrio superior entre rendimiento, estabilidad y explicabilidad, especialmente en un contexto inmobiliario donde las relaciones entre variables suelen ser no lineales, multicolineales y parcialmente ruidosas.

El pipeline inici√≥ con una estandarizaci√≥n global mediante *StandardScaler*, necesaria para evitar que variables con escalas dis√≠miles dominaran las componentes principales o influyeran desproporcionadamente en la regularizaci√≥n. Luego se aplic√≥ un paso de PCA configurado para retener el 80 % de la varianza acumulada, actuando como un filtro inicial que aten√∫a colinealidades profundas mientras conserva se√±ales relevantes para el predictor. Paralelamente, se calcul√≥ la informaci√≥n mutua sobre las variables originales, seleccionando las 30 m√°s relevantes en t√©rminos de dependencia estad√≠stica con el precio de venta; esta estrategia permiti√≥ mantener trazabilidad interpretativa y preservar atributos con significado sem√°ntico en el contexto inmobiliario.

Luego, el conjunto temporal de features pas√≥ por un proceso de *Recursive Feature Elimination* utilizando un RandomForestRegressor como estimador base. Este paso introdujo una capa de selecci√≥n supervisada, capaz de ponderar la importancia de cada variable seg√∫n su contribuci√≥n real al desempe√±o. El refinamiento final consisti√≥ en aplicar *LassoCV*, que elimin√≥ caracter√≠sticas redundantes mediante regularizaci√≥n L1, generando as√≠ un subconjunto compacto y menos propenso al sobreajuste. Finalmente, el modelo resultante fue evaluado mediante un RandomForestRegressor con validaci√≥n cruzada (cv=5), permitiendo obtener un estimador fiable del rendimiento medio y del comportamiento generalizado del pipeline compuesto.

---

## Interpretaci√≥n de los Resultados Observados

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica10/results_table.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={300}
  />
</div>

La tabla de resultados sintetiza el desempe√±o de cada m√©todo individual ‚ÄîMutual Information, RFE, PCA y LassoCV‚Äî junto con el del pipeline h√≠brido que los combina de forma articulada. Cada fila representa una metodolog√≠a de selecci√≥n y muestra sus valores de RMSE, R¬≤, interpretabilidad y tiempo de ejecuci√≥n. La primera observaci√≥n notable es que **Mutual Information**, con 30 features, presenta un RMSE relativamente bajo (26,573) y un R¬≤ de 0.912, lo cual indica que la relaci√≥n estad√≠stica entre variables y objetivo contiene informaci√≥n sustancial sobre la estructura del problema. Este enfoque destaca por su alta interpretabilidad, dado que retiene atributos originales, f√°cilmente rastreables al dominio.

El m√©todo **RFE (RF)** reduce el conjunto a 20 variables y consigue un R¬≤ de 0.905. Aunque su desempe√±o es ligeramente inferior al de MI, su car√°cter supervisado le permite detectar patrones que dependen directamente del comportamiento del modelo, m√°s all√° de la correlaci√≥n o la dependencia estad√≠stica pura. El costo computacional es considerablemente m√°s alto ‚Äî62 segundos‚Äî evidenciando que la selecci√≥n iterativa con Random Forest es intensiva cuando se busca un subconjunto √≥ptimo.

Por otro lado, **PCA** reduce las caracter√≠sticas a solo 18 componentes, pero al precio de una interpretabilidad baja. Su R¬≤ de 0.89 confirma que, aunque es efectivo en capturar varianza global, su naturaleza no supervisada limita su capacidad predictiva. En este caso, el modelo pierde acceso a la sem√°ntica original de las variables, lo que es especialmente cr√≠tico en an√°lisis inmobiliarios donde la interpretabilidad influye en el valor del an√°lisis.

**LassoCV**, con 38 variables retenidas, exhibe el desempe√±o m√°s d√©bil (R¬≤ = 0.837). Esto sugiere que la regularizaci√≥n L1 elimina par√°metros de manera efectiva, pero la estructura no lineal del problema dificulta que un enfoque puramente lineal capture toda la complejidad de Ames.

Finalmente, la fila correspondiente al **pipeline h√≠brido (PCA + MI + RFE + Lasso)** muestra que, aunque combina m√∫ltiples t√©cnicas, no busca maximizar √∫nicamente el R¬≤, sino encontrar un equilibrio entre generalizaci√≥n, estabilidad, tama√±o de feature space y interpretabilidad. Con 18 variables retenidas y un tiempo razonable, el pipeline logra un R¬≤ de 0.821, inferior al de los m√©todos individuales, pero con la ventaja de ofrecer una arquitectura m√°s compacta, robusta y metodol√≥gicamente equilibrada. El mensaje clave es que su fortaleza no reside en superar cada m√©todo aislado, sino en proporcionar un enfoque vers√°til y reproducible, ideal para etapas avanzadas de MLOps y despliegue productivo.

---

## Conclusi√≥n

El an√°lisis global del experimento demuestra que ning√∫n m√©todo de selecci√≥n de caracter√≠sticas es universalmente superior. Mutual Information sobresale en interpretabilidad y desempe√±o estad√≠stico; RFE destaca por captar relevancia supervisada; PCA es eficiente para condensar la estructura de correlaci√≥n; LassoCV contribuye a la eliminaci√≥n autom√°tica de ruido; y Random Forest aporta estabilidad predictiva y capacidad para manejar no linealidades. Sin embargo, la verdadera potencia emerge cuando estos enfoques se integran en un pipeline h√≠brido que respeta la complejidad del dominio y combina fortalezas de t√©cnicas complementarias.

Esta extensi√≥n confirma que procesos de selecci√≥n multifase permiten construir modelos m√°s compactos, menos propensos al sobreajuste y mejor adaptados a un ciclo de vida reproducible. La combinaci√≥n de m√©todos estad√≠sticos, model-based y regularizados responde a un paradigma moderno de ingenier√≠a de caracter√≠sticas donde el objetivo ya no es solo mejorar m√©tricas de precisi√≥n, sino asegurar transparencia, consistencia y trazabilidad. En este sentido, el pipeline h√≠brido refleja pr√°cticas alineadas con CRISP-DM y con enfoques educativos de MLOps, promoviendo no solo modelos eficaces sino tambi√©n confiables y auditables.

--

## Evidencias

Para consultar el c√≥digo √≠ntegro, las funciones aplicadas, la generaci√≥n de gr√°ficos y los resultados intermedios de la pr√°ctica, se adjunta el notebook original:

üìé **Google Colab:** [Abrir notebook](https://colab.research.google.com/drive/18mQI0b90X8ZalLC6BSKmG_JF9plzYB0h?usp=sharing)

Esta Actividad bonus se encuentra al final.

---
