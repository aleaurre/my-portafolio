---
title: "Ingenier√≠a de Features y Codificaci√≥n Avanzada: Una Arquitectura √ìptima para Datos Categ√≥ricos."
publishedAt: "2025-10-16"
tag: "Curso: Ingenier√≠a de Datos"
image: "/practica9/portada.jpg"
---

# Ingenier√≠a de Features y Codificaci√≥n Avanzada de Variables Categ√≥ricas
Modelo, Dimensionalidad e Interpretabilidad en un Pipeline Mixto Productivo

## Marco Te√≥rico

El tratamiento adecuado de variables categ√≥ricas constituye uno de los pilares del feature engineering moderno. Dado que los algoritmos de aprendizaje supervisado trabajan de forma nativa con representaciones num√©ricas, la elecci√≥n del m√©todo de codificaci√≥n afecta profundamente el comportamiento del modelo. Aspectos como estabilidad, tendencia al overfitting, interpretabilidad y costo computacional dependen directamente de c√≥mo se representen las categor√≠as.

En este trabajo se comparan tres grandes enfoques: Label Encoding, One-Hot Encoding y Target Encoding con smoothing, adem√°s de un pipeline ramificado que combina estrat√©gicamente los anteriores seg√∫n cardinalidad. La hip√≥tesis gu√≠a es que no existe un encoding universalmente √≥ptimo, sino que su rendimiento depende de la distribuci√≥n de categor√≠as, su cardinalidad y la interacci√≥n con el modelo base.

## Objetivos
- Comparar impacto en precisi√≥n, AUC, F1 y dimensionalidad.
- Dise√±ar un pipeline modular y escalable basado en ColumnTransformer.
- Analizar Feature Importances y SHAP para evaluar interpretabilidad.
- Discutir implicancias √©ticas y de fairness en modelos con variables sensibles.
- Integrar todo el an√°lisis en formato reproducible y t√©cnicamente riguroso.

---

## Metodolog√≠a

En esta pr√°ctica desarroll√© un proceso completo de feature engineering orientado al tratamiento avanzado de variables categ√≥ricas, con el objetivo de evaluar c√≥mo diferentes t√©cnicas de codificaci√≥n afectan el rendimiento, la interpretabilidad y la eficiencia de un modelo de clasificaci√≥n. Comenc√© realizando un an√°lisis detallado de la cardinalidad de cada variable para identificar cu√°les eran candidatas √≥ptimas para Label Encoding, One-Hot Encoding o Target Encoding, dado que la estructura de las categor√≠as condiciona fuertemente el riesgo de explosi√≥n dimensional, el tiempo de c√≥mputo y el potencial de overfitting. A partir de este diagn√≥stico, dise√±√© e implement√© m√∫ltiples pipelines experimentales, incluyendo un pipeline ramificado con ColumnTransformer que aplica autom√°ticamente el m√©todo de codificaci√≥n m√°s adecuado seg√∫n la naturaleza de cada variable, garantizando reproducibilidad y evitando data leakage mediante validaci√≥n cruzada.

Adem√°s de comparar los encodings en t√©rminos de m√©tricas predictivas ‚Äîaccuracy, AUC, F1-score‚Äî tambi√©n analic√© su impacto en la cantidad final de features, el tiempo de entrenamiento y la estabilidad del modelo. Complement√© este estudio con herramientas de interpretabilidad como feature importance y SHAP, lo que permiti√≥ examinar no solo el desempe√±o del modelo, sino tambi√©n c√≥mo la elecci√≥n del encoding modifica la relevancia atribuida a cada variable. Finalmente, extend√≠ el an√°lisis con t√©cnicas adicionales e integr√© una reflexi√≥n sobre fairness y aplicabilidad pr√°ctica, construyendo as√≠ una perspectiva integral que conecta las decisiones de ingenier√≠a con su efecto real en la calidad y transparencia del modelo.

---

## Resultados ‚Äî Comparaci√≥n de Modelos

<table>
<thead>
<tr>
<th>M√©todo</th><th>Accuracy</th><th>AUC-ROC</th><th>F1-Score</th><th>Tiempo (s)</th><th>N¬∫ Features</th>
</tr>
</thead>
<tbody>
<tr><td>Label Encoding</td><td>0.8610</td><td>0.9101</td><td>0.6883</td><td>0.18</td><td>14</td></tr>
<tr><td>One-Hot (baja card.)</td><td>0.8471</td><td>0.8998</td><td>0.6615</td><td>0.17</td><td>30</td></tr>
<tr><td>Target Encoding (alta card.)</td><td>0.8029</td><td>0.8274</td><td>0.5551</td><td>0.20</td><td>6</td></tr>
<tr><td>Pipeline Branched</td><td>0.8472</td><td>0.8998</td><td>0.6624</td><td>0.19</td><td>30</td></tr>
</tbody>
</table>

---

### Cardinalidad de Variables Categ√≥ricas

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica9/cardinal.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={400}
  />
</div>

La gr√°fica muestra con claridad c√≥mo algunas variables del dataset presentan una cantidad elevada de categor√≠as √∫nicas, particularmente native-country con 42 niveles. Esta observaci√≥n es clave, ya que la cardinalidad influye directamente en la elecci√≥n del m√©todo de codificaci√≥n: mientras OHE funciona bien para cardinalidades bajas, se vuelve ineficiente y propenso a la explosi√≥n dimensional en casos como este.

El an√°lisis tambi√©n permite detectar variables de baja y media cardinalidad, facilitando una estrategia h√≠brida. Identificar estos grupos desde el inicio evita sobreajustar el modelo y permite planificar un pipeline m√°s estable. La segmentaci√≥n categ√≥rica es un paso fundamental que, aunque frecuentemente subestimado, tiene un impacto directo en la capacidad generalizadora del modelo.

---

### Comparaci√≥n de M√©tricas entre M√©todos de Encoding

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica9/Encoding.png"
    alt="Boxplots mostrando diferencias de escala"
    width={1000}
    height={600}
  />
</div>

Esta matriz de gr√°ficos sintetiza c√≥mo cada m√©todo afecta distintas dimensiones del rendimiento. Se observa que Label Encoding alcanza los mejores valores de accuracy y AUC, aunque esto puede deberse parcialmente a que introduce relaciones ordinales artificiales que los √°rboles pueden aprovechar. Por otra parte, One-Hot Encoding, pese a su buen desempe√±o, incrementa el n√∫mero de columnas, lo que impacta el tiempo de entrenamiento en modelos m√°s complejos.

Lo m√°s interesante surge al comparar Target Encoding, que logra una reducci√≥n extrema de dimensionalidad con solo seis columnas. Aunque su precisi√≥n es menor en este dataset, su ventaja se vuelve evidente en contextos donde la cardinalidad es a√∫n mayor, o en modelos sensibles a la dimensionalidad. En s√≠ntesis: la relaci√≥n entre encoding y rendimiento no es lineal, y comprender estas interacciones es indispensable para dise√±ar arquitecturas robustas.

---

### Importancia de Variables (Random Forest)

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica9/importance.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={300}
  />
</div>

La gr√°fica revela que las variables num√©ricas, como edad, peso poblacional y educaci√≥n, concentran la mayor parte de la importancia del modelo. Esto es consistente con literatura previa en an√°lisis socioecon√≥mico, donde la edad y el nivel educativo suelen ser predictores significativos del nivel de ingresos. De forma interesante, variables categ√≥ricas como estado civil tambi√©n aparecen destacadas cuando se codifican adecuadamente.

Este comportamiento pone en evidencia c√≥mo la calidad del encoding afecta no solo las m√©tricas finales, sino la interpretaci√≥n y transparencia del modelo. Un encoding deficiente podr√≠a ocultar relaciones reales o amplificar artefactos estad√≠sticos. Aqu√≠, la combinaci√≥n de num√©ricas + categ√≥ricas bien representadas construye un modelo m√°s explicable y alineado con comportamientos demogr√°ficos reales.

---

### Importancia por Tipo de Encoding

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica9/compaencoding.png"
    alt="Boxplots mostrando diferencias de escala"
    width={900}
    height={500}
  />
</div>

Al comparar las variables m√°s influyentes bajo distintos m√©todos de codificaci√≥n, se aprecia c√≥mo cada t√©cnica resalta distintos patrones. En Label Encoding, algunas categor√≠as reciben valores num√©ricos altos que los √°rboles interpretan como m√°s influyentes, aun cuando no exista relaci√≥n ordinal. En contraste, el One-Hot despliega un conjunto m√°s equilibrado de variables, permitiendo que el modelo distinga relaciones de forma granular.

Target Encoding, por su parte, concentra importancia en pocas variables, especialmente num√©ricas, debido a la reducci√≥n de dimensiones. Esto explica por qu√© su interpretabilidad tiende a ser m√°s sencilla, pero tambi√©n m√°s dependiente del smoothing utilizado. Estas diferencias demuestran que la elecci√≥n del m√©todo de codificaci√≥n no solo modifica el rendimiento, sino el perfil de explicaci√≥n del modelo.

---

### Distribuci√≥n de Features

<div style={{ display: "flex", justifyContent: "center", margin: "24px 0" }}>
  <Image
    src="/practica9/disfeatures.png"
    alt="Boxplots mostrando diferencias de escala"
    width={800}
    height={300}
  />
</div>

El histograma evidencia una distribuci√≥n fuertemente asim√©trica, donde pocas variables concentran una fracci√≥n significativa de la importancia. Este fen√≥meno es com√∫n en modelos que reflejan inequidades estructurales: caracter√≠sticas como educaci√≥n, edad y horas trabajadas suelen ser altamente predictoras de ingresos.

La l√≠nea vertical marca la importancia promedio. La mayor√≠a de las variables categ√≥ricas codificadas se ubican muy por debajo, lo que sugiere que, aunque agregan valor, su contribuci√≥n es m√°s contextual que decisiva. Esto abre una discusi√≥n importante sobre fairness: las variables demogr√°ficas tienen poco peso relativo, lo que reduce riesgo de sesgo, pero requiere an√°lisis adicional con m√©tricas de igualdad.

--- 

## Discusi√≥n Cr√≠tica

Uno de los aprendizajes m√°s relevantes es que la cardinalidad dicta la estrategia de codificaci√≥n. Ning√∫n m√©todo es universalmente superior: cada uno implica compromisos entre estabilidad, dimensionalidad e interpretabilidad. As√≠, los pipelines ramificados se presentan como la soluci√≥n m√°s madura, permitiendo asignar el encoding adecuado a cada variable.

Adem√°s, se confirma que la interpretabilidad no debe abordarse como un paso posterior al modelado, sino como un criterio que gu√≠a decisiones desde el preprocesamiento. M√©todos como SHAP y Feature Importance revelan c√≥mo decisiones tempranas afectan no solo predicci√≥n, sino tambi√©n transparencia y responsabilidad del modelo.

---

## Implicancias √âticas y Fairness

Trabajar con datos demogr√°ficos exige considerar sesgos potenciales. Variables como g√©nero, raza y estado civil pueden introducir inequidades si el modelo aprende patrones discriminatorios. Aunque en este trabajo no se evidenci√≥ una influencia desproporcionada de estas variables, se recomienda aplicar m√©tricas de equidad como:
- Equal Opportunity Difference
- Demographic Parity
- Disparate Impact
Un modelo sin evaluaci√≥n de fairness carece de validez para aplicaciones sociales o empresariales sensibles.

---

## Referencias
- G√©ron, A. Hands-On Machine Learning with Scikit-Learn & TensorFlow.
- Kuhn & Johnson. Feature Engineering and Selection.
- Scikit-Learn Documentation.
- Category Encoders Documentation.

--

## Evidencias

Para consultar el c√≥digo √≠ntegro, las funciones aplicadas, la generaci√≥n de gr√°ficos y los resultados intermedios de la pr√°ctica, se adjunta el notebook original:

üìé **Google Colab:** [Abrir notebook](https://colab.research.google.com/drive/1oEOfzJv0kP6W4ZsCaXAyWumKknSTisuH?usp=sharing)

---